---
title: "combiroc"
output:
  html_document: 
    df_print: paged
  pdf_document: 
    latex_engine: xelatex
    df_print: paged
vignette: >
  %\VignetteIndexEntry{combiroc}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include=FALSE}
library(combiroc)
```


This markdown shows a representative **combiroc** package analysis workflow in which is assessed the marker combinations performance in classifying samples of the proteomic dataset from [Zingaretti et al. 2012](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3518104/) (the one also used in the CombiROC web app tutorial).  This dataset contains multi-marker signatures for Autoimmune Hepatitis (AIH) for samples clinically diagnosed as “abnormal” (class A) or "normal" (class B).

## Data loading

The dataset to be analysed should be in text format, which can be comma, tab or semicolon separated:

- The 1st column must contain unique patient/sample IDs.
- The 2nd column must contain the class to which each sample belongs.
- The classes must be exactly 2 and they must be written in character format. 
- From the 3rd column on, the dataset must contain numerical values that represent the signal corresponding to the markers abundance in each sample (marker-related columns). 
- Marker-related columns can be called 'Marker1, Marker2, Marker3, ...' or can be called directly with the gene/protein name, but "-" is not allowed in the column name. 

The **load_data()** function uses a customized **read.table()** function that checks the conformity of the dataset format. If all the checks are passed, it reorders alphabetically the marker-related columns depending on marker names (necessary for a proper computation of combinations), and it forces "Class" as 2nd column name.
The loaded dataset is assigned to the "*data*" object.
```{r}
data <- load_data("../data/demo_data.csv", sep=';')
data
```
The very same dataset has been included in **combiroc** package as a demo dataset, that can be directly called typing *demo_data*. 
```{r}
demo_data
```
The **CombiROC_long()** is a function that simply wraps dyplr::**pivot_longer()**
function, and it's used to reshape the data in long format. Data in long format is required to obtain the boxplot of the next function. The obtained data in long format is assinged to "*data_long*" object.
```{r}
data_long <- CombiROC_long(data)
data_long
```

## Markers distribution overview

Since the target of the analysis is the identification of marker combinations capable to correctly classify samples, the user should choose a signal threshold to define the positivity for a given marker/combination. This threshold should:

- Positively select most samples belonging to the case class ("A" in this case), which values must be above the signal threshold.
- Negatively select most control samples ("B"), which values must be below the signal threshold. 

Usually this threshold is suggested by the guidelines of the kit used for the analysis (e.g. mean of buffer signal + n standard deviations). However, it is a good practice to always check the distribution of signal intensity of the dataset. To help the user with this operation, the **markers_distribution()** have been implemented. This function takes as input data in long format ("*data_long*"), and returns a named list (here assigned to '*distribution*') containing the following objects:

- 'Boxplot': a boxplot showing the distribution of each marker values for both classes.
- "ROC": a ROC curve showing how many real positive samples would be found positive (SE) and how many real negative samples would be found negative (SP) in function of signal threshold. NB: these SE and SP are refereed to the signal intensity threshold considering all the markers together; it is NOT equal to the SE/SP of a single marker/combination (shown later in **Sensitivity and specificity**).
- "Coord": a dataframe that contains the coordinates of the above described "ROC" (threshold, SP and SE) that have at least a min SE (40 by default) and a min SP (80 by default). These limits can be set manually by specifying  min_SE and min_SP.
- "Density_plot": a density plot showing the distribution of the signal intensity values for both the classes. In addition, the function allows the user to set both the y_lim and x_lim values to provide a better visualization.
- "Density_summary": a summary statistics of the density plot.

In case of lack of a priori known threshold the user can set set signalthr_prediction= TRUE. In this way the function provides a "suggested signal threshold" that corresponds to the median of the singnal threshold values (in "Coord") at which SE/SP are grater or equal to their set minimal values (min_SE and min_SP), and it adds this threshold on the "Density_plot" object as a dashed black line. The use of the median allows to pick a threshold whose SE/SP are not too close to the limits (min_SE and min_SP), but it is recommended to always inspect "Coord" and choose the most appropriate signal threshold by considering SP, SE and Youden index.



```{r}
distribution <- markers_distribution(data_long, case_class = 'A', y_lim = 0.0015, x_lim = 3000, signalthr_prediction = TRUE, min_SE = 40, min_SP = 80, boxplot_lim = 2000)
distribution$Boxplot
distribution$ROC
distribution$Coord
distribution$Density_plot
distribution$Density_summary
```


## Combinatorial analysis

**Combi()** function computes the marker combinations and counts their corresponding positive samples for each class (once thresholds are selected). A sample, to be considered positive for a given combination, must have a value higher than a given signal threshold (signalthr) for at least a given number of markers composing that combination (combithr). In this case signalthr is set at 450 while combithr is set at 1, in order to reproduce both the results reported in [Mazzara et. al 2017](https://www.nature.com/articles/srep45477) (CombiROC paper) and also the tutorial of the web app with default thresholds. 

As discussed before, signalthr should be set depending on the guidelines of the kit used for the analysis or by an accurate inspection of signal intensity distribution (see **Markers distribution overview** section). In this specific case 450 is the mean of the intensity of buffer + 3 standard deviation (see [Bombaci & Rossi 2019](https://link.springer.com/protocol/10.1007%2F978-1-4939-9164-8_16)).
In case of lack of guidelines, it's recommended the inspection of data distribution (see **markers_distribution()**). 

combithr, instead, should be set exclusively depending on the needed stringency. In this example the obtained combinations dataframe is assigned to "*tab*" object.

```{r}
tab<-Combi(data, signalthr = 450, combithr = 1)
tab
```
## Sensitivity and specificity

**SE_SP()** function calulates:

- Sensitivity (SE) and specificty (SP) of each combination for each class.
- The number of markers composing each combination (#Markers). 

SE of case class ("A") is calculated dividing the number of positive samples by the total sample of case class (% of positive "A" samples), while case class SP is calculated subtracting SE to 100 (% of negative "A" samples).

SE of control class ("B") is calculated dividing the number of positive samples by the total sample of control class (% of positive "B" samples), while SP is calculated subtracting SE to 100 (% of negative "B" samples).

Thus, the SE of a given combination (capability to find real positives/cases) corresponds to the SE of the case class (in this case "A"), while its SP (capability to exclude real negatives/controls) corresponds to the SP of the control class (in this case "B").
The obtained dataframe with SE, SP and number of markers is assigned to "*mks*" object. 

```{r}
mks <- SE_SP(data, tab)
mks
```
## Selection of combinations

**ranked_combs()** is a function that, after having specified the case class ("A" in this case),  ranks the combinations by the Youden index in order to show the combinations with the highest SE (of cases) and SP (of controls) on the top, facilitating the user in the selection of the best ones. The Youden is calculated in this way:
$$
 Youden = SE+SP
$$
The user can also set (not mandatory) a minimal value of SE and/or SP that a combination must have to be selected.
In this case the minimal values of SE and SP are set, respectively, to 40 and 80, in order to reproduce both the gold combinations selection reported in [Mazzara et. al 2017](https://www.nature.com/articles/srep45477) and also the tutorial of the web app with default thresholds. The obtained dataframe with ranked combination is assigned to "*rmks*" object. 


```{r}
rmks<- ranked_combs(data, mks, case_class = 'A', min_SE = 40, min_SP = 80)
rmks
```

## ROC curves

To allow an objective comparison of combinations, the function **ROC_reports()** applies the Generalised Linear Model (stats::**glm()** with family= binomial) for each selected one. The resulting predictions are then used to compute ROC curves (with pROC::**roc()**) and their corresponding metrics which are both returned by the function as a named list object (in this case called "*reports*").  This function requires as input:

- The data object ("*data*") obtained with **load_data()**.
- The table with combinations and corresponding positive samples counts (*"tab"*), obtained with **Combi()**.

In addition, the function requires to specify the class case, the single markers and/or the combinations of interest. 
In this example have been chosen a single marker (Marker1) and 2 combinations (11 and 15).
```{r}
reports <-ROC_reports(data, markers_table = tab, case_class = 'A',
                      single_markers =c('Marker1'), selected_combinations = c(11,15))
```
"*reports*" contains 3 named objects:

- "Plot": a ggplot object with the ROC curves of the selected combinations.
- "Metrics": a dataframe with the metrics of the roc curves (AUC, opt. cutoff, etc ...).
- "Models": The list of models that have been computed and then used to classify the samples (the equation for each selected combination).

```{r}
reports$Plot
reports$Metrics
reports$Models
```
## Retrieving composition of combinations

**show_markers()** returns a data.frame containing the composition of each combination of interest. It requires as input one or more combinations (only their numbers), and the table with combinations and corresponding positive samples counts (*"tab"*, obtained with **Combi()**).
```{r}
show_markers(selected_combinations =c(11,15), markers_table = tab)
```

## Retrieving combinations containing markers of interest

**combs_with()** returns the combinations containing all the markers of interest. It requires as input one or more single marker, and the table with combinations and corresponding positive samples counts (*"tab"*, obtained with **Combi()**). The list with the combinations containing all the markers is assigned to *"combs_list"* object.
```{r}
combs_list <- combs_with(markers=c('Marker1', 'Marker3'), markers_table = tab)
combs_list
```

## Results explanation

To be more clear about the interpretation of results, this section will be focused on "Combination 11" (Marker1+Marker2+Marker3) which has an optimal cutoff equal to  0.216 (see **ROC curves**, *reports$Metrics*) .
This is the equation used to compute the predictions:

$$
f(x)=β_0+β_1x_1+β_2x_2+ β_3x_3 +...+β_nx_n
$$


Instead, the predicted probabilities have been calculated with the sigmoid function:

$$
p(x) =  \frac{\mathrm{1} }{\mathrm{1} + e^{-f(x)} }  
$$



For "Combination 11", the predictions have been calculated in this way (see **ROC curves**, reports['Models']):


$$
f(x)=    -17.0128  +  1.5378 *log(Marker1 + 1)  +  0.9176 *log(Marker2 + 1) + 0.5706* log(Marker3 + 1)$$
Predictions (f(x) values) of 'Combination 11' can be visualized with the following command: 
```{r}
head(predict(reports$Models$`Combination 11`, type='link')) # link = f(x)
head(predict(reports$Models$`Combination 11`, type='link'))  # link = f(x)
```


Prediction probabilities (p(x) values) of 'Combination 11' can be instead visualized by typing: 
```{r}
head(predict(reports$Models$`Combination 11`, type='response')) # response = p(x)
head(predict(reports$Models$`Combination 11`, type='response')) # response = p(x)
```


Finally, the comparison between the prediction probability and the optimal cutoff determines the classification of each sample by following this rule:


$$
C(x) = 
\begin{cases} 
      1 & {p}(x) > opt. cutoff \\
      0 & {p}(x) \leq opt.cutoff 
\end{cases}
$$



Specifically, for "Combination 11":

- Samples with p(x) higher than 0.216 are classified as "positives" (1).
- Samples with p(x) lower or equal to 0.216 are classified as "negatives" (0).

Thus, using 0.216 as cutoff, "Combination 11" is able to classify the samples in the dataset with a SE equal to 95.0%, SP equal to 86.9%, and accuracy equal to 88.8% (see **ROC curves**, *reports$Metrics*]).

## Classification of new samples

CombiROC package also offers the possibility to exploit the models for each selected marker/combination obtained with **ROC_reports()**  (here assigned to *reports$Models*) to directly classify new samples.

The unclassified dataset must be similar to the dataset used for the previous combinatorial analysis (with the same markers, and obviously without the 'Class' column).

To load the dataset with the new unclassified samples  **load_unclassified_data()** has been implemented. This function is analogue to **load_data()** because it loads the same kind of files and it performs the same format checks, with the exception of what concerns 'Class' column (which is not present in unclassified datasets).  

For explanatory purposes, in the following example has been used a 'synthetic' unclassified dataset ('data/unclassified_proteomic_data.csv') obtained by randomly picking 20 samples from the already classified dataset (*data*).
The loaded unclassified sample is here assinged to *unc_data*. 
```{r}
unc_data <- load_unclassified_data(data = '../data/demo_unclassified_data.csv', sep = ',')
unc_data
```
The very same dataset has been included in **combiroc** package as an unclassified demo dataset, that can be directly called typing *demo_unclassified_data*. 
```{r}
demo_unclassified_data
```

The prediction of the class can be achieved with **Classify()**:
a function that applies the previously calculated models to the unclassified dataset and classifies the samples accordingly to the very same rule shown in the end of the **Results explanation** section.

This function takes as inputs:

- the unclassified dataset containing the new samples to be classified (*unc_data*).
- the list of models that have been previously computed by **ROC_reports()** (*reports$Models*).
- the list of metrics that have been previously computed by **ROC_reports()** (*reports$Metrics*).

In addition the user can set the labels of the predicted class (setting Positive_class and Negative_class), otherwise they will be 1 for positive samples and 0 for the negative samples by default (see the rule shown in the end of the **Results explanation** section).

The function returns a named list of data.frames (here assigned to *cl_data*), one for each marker/combination contained in the list of models (*reports$Models*), containing the predicted class for each sample.

To visualize a data.frame containing the classification performed by a model corresponding to a given marker/combination ('Combination 11' in the following example) it is sufficient to 
call the data.frame list and specify it.

```{r}
cl_data <- Classify(unc_data, Models =  reports$Models, Metrics = reports$Metrics, Positive_class = 'A', Negative_class = 'B')
cl_data$`Combination 11`
```
