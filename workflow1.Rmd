---
title: "CombiROC workflow"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# needed libraries
library(tidyr)
library(dplyr)
library(ggplot2)
library(gtools)
library(pROC)
library(stringr)
# source from file the combiroc custom functions
#source("C:/Users/rossiriccardo/R/combiroc/combiroc_functions.R")
source("~/Desktop/ivan/INGM/combiroc/combiroc_functions.R")
```


This markdown shows a representative CombiROC analysis workflow in which is assessed the marker combinations performance in classifying samples of the proteomic dataset from Zingaretti et al. 2012 (the one also used in the CombiROC web app tutorial).  This dataset contains multi-marker signatures for Autoimmune Hepatitis (AIH) for samples clinically diagnosed as “abnormal” (class A) or "normal" (class B).

## Data loading

The dataset to be analysed should be in text format, which can be comma, tab or semicolon separated:

- The 1st column must contain patient/sample IDs as characters.
- The 2nd column must contain the class to which each sample belongs.
- The classes must be exactly 2 and they must be written in character format. 
- From the 3rd column on, the dataset must contain numerical values that represent the signal corresponding to the markers abundance in each sample (marker-related columns). 
- Marker-related columns can be called 'Marker1, Marker2, Marker3, ...' or can be called directly with the gene/protein name, but "-" is not allowed in the column name. 

The **load()** function uses a customized **read.table()** function that checks the conformity of the dataset format. If all the checks are passed, it reorders alphabetically the marker-related columns depending on marker names (necessary for a proper computation of combinations), and it forces "Class" as 2nd column name.
The loaded dataset is assigned to the "*data*" object.
```{r}
data <- load("data/demo_5Ags.csv", sep=';')
head(data)
tail(data)
```
The **CombiROC_long()** is a function that simply wraps dyplr::**pivot_longer()**
function, and it's used to reshape the data in long format. Data in long format is required to obtain the boxplot of the next function. The obtained data in long format is assinged to "*data_long*" object.
```{r}
data_long <- CombiROC_long(data)
head(data_long)
tail(data_long)
```

## Markers distribution overview

**markers_overview()**, as suggested by the name, provides an overview of the expression of each marker in the two classes of the dataset. This function takes as input data in long format ("*data_long*"), and returns a named list (in this case called *overview*).
This list contains two objects:

- 'Plot': a boxplot whose y max value can be set, in order to allow a better visualization (zoom only, no data loss).
- 'Summary': a data.frame with a summary statics of the overall expression of markers in the two classes of the dataset.
```{r}
overview <- markers_overview(data_long, ylim =2000)
overview$Plot
overview$Summary
```


## Combinatorial analysis

**Combi()** function computes the marker combinations and counts their corresponding positive samples for each class (once thresholds are selected). A sample, to be considered positive for a given combination, must have a value higher than a given signal threshold (signalthr) for at least a given number of markers composing that combination (combithr). In this case signalthr is set at 450 while combithr is set at 1, in order to reproduce both the results reported in Mazzara et. al 2017 (CombiROC paper) and also the tutorial of the web app with default thresholds. In general signalthr should be set by inspecting the previous boxplot and considering the median of markers expression in both classes. Since the target of the analysis is the identification of marker combinations capable to correctly classify samples, the user should choose a signalthr that:

- Positively selects most samples belonging to the case class ("A" in this case), which must be above signalthr.
- Negatively selects most control samples ("B"), which must be below signalthr. 

combithr should be set exclusively depending on the needed stringency. In this example the obtained combinations dataframe is assigned to "*tab*" object.

```{r}
tab<-Combi(data, signalthr = 450, combithr = 1)
head(tab)
tail(tab)
```
## Sensitivity and specificity

**SE_SP()** function calulates:

- Sensitivity (SE) and specificty (SP) of each combination for each class.
- The number of markers composing each combination (#Markers). 

SE of case class ("A") is calculated dividing the number of positive samples by the total sample of case class (% of positive "A" samples), while case class SP is calculated subtracting SE to 100 (% of negative "A" samples).

SE of control class ("B") is calculated dividing the number of positive samples by the total sample of control class (% of positive "B" samples), while SP is calculated subtracting SE to 100 (% of negative "B" samples).

Thus, the SE of a given combination (capability to find real positives/cases) corresponds to the SE of the case class (in this case "A"), while its SP (capability to exclude real negatives/controls) corresponds to the SP of the control class (in this case "B").
The obtained dataframe with SE, SP and number of markers is assigned to "*mks*" object. 

```{r}
mks <- SE_SP(data, tab)
head(mks)
tail(mks)
```
## Selection of combinations

**ranked_combs()** is a function that, after having specified the case class ("A" in this case),  ranks the combinations by a ranking score in order to show the combinations with the highest SE (of cases) and SP (of controls) on the top, facilitating the user in the selection of the best ones. The score is calculated in this way:
$$
 score = 2(SE*SP)/(SE+SP)
$$
The user can also set (not mandatory) a minimal value of SE and/or SP that a combination must have to be selected.
In this case the minimal values of SE and SP are set, respectively, to 40 and 80, in order to reproduce both the gold combinations selection reported in Mazzara et. al 2017 and also the tutorial of the web app with default thresholds. The obtained dataframe with ranked combination is assigned to "*rmks*" object. 


```{r}
rmks<- ranked_combs(data, mks, case_class = 'A', min_SE = 40, min_SP = 80)
rmks
```

## ROC curves

To allow an objective comparison of combinations, the function **ROC_reports()** applies the Generalised Linear Model (stats::**glm()** with family= binomial) for each selected one. The resulting predictions are then used to compute ROC curves (with pROC::**roc()**) and their corresponding metrics which are both returned by the function as a named list object (in this case called "*reports*").  This function requires as input:

- The data object ("*data*") obtained with **load()**.
- The table with combinations and corresponding positive samples counts (*"tab"*), obtained with **Combi()**.

In addition, the function requires to specify the class case, the single markers and/or the combinations of interest. 
Direction can be set (not mandatory) in order to specify if the number of cases is <= ('<') or >= ('>') the number of controls.  Otherwise the direction will be automatically set (default= 'auto'), defining the group in which the median is higher as case group (see [roc() documentation](https://www.rdocumentation.org/packages/pROC/versions/1.17.0.1/topics/roc)). 
In this example have been chosen a single marker (Marker1) and 2 combinations (11 and 15).
```{r}
reports <-ROC_reports(data, markers_table = tab, case_class = 'A',
                      single_markers =c('Marker1'), selected_combinations = c(11,15), direction = '<')
```
"*reports*" contains 3 named objects:

- "Plot": a ggplot object with the ROC curves of the selected combinations.
- "Metrics": a dataframe with the metrics of the roc curves (AUC, opt. cutoff, etc ...).
- "Models": The list of models that have been computed and then used to classify the samples (the equation for each selected combination).

```{r}
reports['Plot']
reports['Metrics']
reports['Models']
```
## Retrieving composition of combinations

**show_markers()** returns a data.frame containing the composition of each combination of interest. It requires as input one or more combinations (only their numbers), and the table with combinations and corresponding positive samples counts (*"tab"*, obtained with **Combi()**).
```{r}
show_markers(selected_combinations =c(11,15), markers_table = tab)
```

## Retrieving combinations containing markers of interest

**combs_with()** returns the combinations containing all the markers of interest. It requires as input one or more single marker, and the table with combinations and corresponding positive samples counts (*"tab"*, obtained with **Combi()**). The list with the combinations containing all the markers is assigned to *"combs_list"* object.
```{r}
combs_list <- combs_with(markers=c('Marker1', 'Marker3'), markers_table = tab)
combs_list
```

## Results

To be more clear about the interpretation of results, this section will be focused on "Combination 11" (Marker1+Marker2+Marker3) which has an optimal cutoff equal to  0.216 (see **ROC curves**, reports['Metrics']) .
This is the equation used to compute the predictions:

$$
f(x)=β_0+β_1x_1+β_2x_2+ β_3x_3 +...+β_nx_n
$$


Instead, the predicted probabilities have been calculated with the sigmoid function:

$$
p(x) =  \frac{\mathrm{1} }{\mathrm{1} + e^{-f(x)} }  
$$



For "Combination 11", the predictions have been calculated in this way (see **ROC curves**, reports['Models']):


$$
f(x)=    -17.0128  +  1.5378 *log(Marker1 + 1)  +  0.9176 *log(Marker2 + 1) + 0.5706* log(Marker3 + 1)$$
Predictions (f(x) values) of 'Combination 11' can be visualized with the following command: 
```{r}
head(predict(reports$Models$`Combination 11`, type='link')) # link = f(x)
tail(predict(reports$Models$`Combination 11`, type='link'))  # link = f(x)
```


Prediction probabilities (p(x) values) of 'Combination 11' can be instead visualized by typing: 
```{r}
head(predict(reports$Models$`Combination 11`, type='response')) # response = p(x)
tail(predict(reports$Models$`Combination 11`, type='response')) # response = p(x)
```


Finally, the comparison between the prediction probability and the optimal cutoff determines the classification of each sample by following this rule:


$$
C(x) = 
\begin{cases} 
      1 & {p}(x) > opt. cutoff \\
      0 & {p}(x) \leq opt.cutoff 
\end{cases}
$$



Specifically, for "Combination 11":

- Samples with p(x) higher than 0.216 are classified as "positives" (1).
- Samples with p(x) lower or equal to 0.216 are classified as "negatives" (0).

Thus, using 0.216 as cutoff, "Combination 11" is able to classify the samples in the dataset with a SE equal to 95.0%, SP equal to 86.9%, and accuracy equal to 88.8% (see **ROC curves**, reports['Metrics']).

